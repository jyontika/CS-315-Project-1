{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 315 - Jaccard Index Analysis\n",
    "\n",
    "Author: Audrey Yip (with help from Eni Mustafaraj)\n",
    "\n",
    "Date: Feb 14 2024\n",
    "\n",
    "**Table of Contents**\n",
    "1. [Importing Data](#sec1)\n",
    "2. [Exploratory Analysis](#sec2)\n",
    "3. [Jaccard Analysis](#sec3)\n",
    "4. [Visualizations](#sec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/5mz_1h8j5c31x__pd0t4xhxw0000gn/T/ipykernel_7703/818026887.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "### 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-14-16-57_save_data_all_videos_AY.csv',\n",
       " '02-14-16-57_data_saved_videos_AY.csv',\n",
       " '.DS_Store',\n",
       " '02-14-19-04_save_data_all_videos_AY.csv',\n",
       " '02-14-16-57_control_data_all_videos_AY.csv',\n",
       " '02-14-19-03_control_data_all_videos_AY.csv',\n",
       " '02-14-19-04_data_saved_videos_AY.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('data') # function lists the content of a directory\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def createPostID(row):\n",
    "    \"\"\"helper function: create a new value using music and author\"\"\"\n",
    "    return f\"{row['music']}_{row['author']}\"\n",
    "\n",
    "# splitter = lambda x: [s.strip() for s in x.split(',') if not s.type() == float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(createPostID, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# use axis=1 to process one row at a time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# split hashtags into list\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhashtag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01min\u001b[39;00m fN:\n\u001b[1;32m     24\u001b[0m     control_dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"helper function: create a new value using music and author\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: [s\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "# create 3 dfs: control data, save data, all data\n",
    "onlyAllData = [f for f in files if 'data_all' in f] # filtering with list comprehension\n",
    "\n",
    "control_dfs = []\n",
    "save_dfs = []\n",
    "all_dfs = []\n",
    "\n",
    "\n",
    "\n",
    "for fN in onlyAllData: # folder with files that have all posts\n",
    "    path = os.path.join('data', fN) # create file path\n",
    "    df = pd.read_csv(path) # create dataframe\n",
    "\n",
    "    # add column to indicate date/time collected\n",
    "    df['collectionTime'] = fN[:11]\n",
    "\n",
    "    # add column with unique post id\n",
    "    df['postID'] = df.apply(createPostID, axis=1) # use axis=1 to process one row at a time\n",
    "\n",
    "    # split hashtags into list\n",
    "    #df['hashtag'] = df['hashtag'].apply(splitter)\n",
    "\n",
    "    if 'control'in fN:\n",
    "        control_dfs.append(df)\n",
    "    else:\n",
    "        save_dfs.append(df)\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "\n",
    "df_control = pd.concat(control_dfs, ignore_index=True)\n",
    "df_save = pd.concat(save_dfs, ignore_index=True)\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"control shape:\", df_control.shape)\n",
    "print(\"save shape:\", df_save.shape)\n",
    "print(\"all data shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>index</th>\n",
       "      <th>music</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>saves</th>\n",
       "      <th>collectionTime</th>\n",
       "      <th>postID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>original sound - ®️ Louieveegang💙</td>\n",
       "      <td>@louieveemoonteenmoonfam</td>\n",
       "      <td>louieveedee</td>\n",
       "      <td>297300</td>\n",
       "      <td>1571</td>\n",
       "      <td>20300</td>\n",
       "      <td>721</td>\n",
       "      <td>02-14-16-57</td>\n",
       "      <td>original sound - ®️ Louieveegang💙_louieveedee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>original sound - dayz915</td>\n",
       "      <td>atodamadre%F0%9F%8F%A7, %F0%9F%A4%99%F0%9F%8F%...</td>\n",
       "      <td>dayz.915</td>\n",
       "      <td>522299</td>\n",
       "      <td>3713</td>\n",
       "      <td>36500</td>\n",
       "      <td>142900</td>\n",
       "      <td>02-14-16-57</td>\n",
       "      <td>original sound - dayz915_dayz.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>original sound - DermDoctor | Dr. Shah</td>\n",
       "      <td>@poblanopepp, dermatographia</td>\n",
       "      <td>dermdoctor</td>\n",
       "      <td>430100</td>\n",
       "      <td>4758</td>\n",
       "      <td>24900</td>\n",
       "      <td>6591</td>\n",
       "      <td>02-14-16-57</td>\n",
       "      <td>original sound - DermDoctor | Dr. Shah_dermdoctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>original sound - 𝐝𝐢𝐧𝐨 🎀</td>\n",
       "      <td>@lashedchars, fy, fyp, fyp%E3%82%B7%E3%82%9Avi...</td>\n",
       "      <td>marschvarl</td>\n",
       "      <td>251</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>02-14-16-57</td>\n",
       "      <td>original sound - 𝐝𝐢𝐧𝐨 🎀_marschvarl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>original sound - AfroSamuraiT</td>\n",
       "      <td>lifehack, lifehacks, challenge, ksi, prime</td>\n",
       "      <td>afrosamuraitt</td>\n",
       "      <td>65200</td>\n",
       "      <td>3487</td>\n",
       "      <td>11700</td>\n",
       "      <td>189</td>\n",
       "      <td>02-14-16-57</td>\n",
       "      <td>original sound - AfroSamuraiT_afrosamuraitt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  index                                   music  \\\n",
       "0      1      0       original sound - ®️ Louieveegang💙   \n",
       "1      1      1                original sound - dayz915   \n",
       "2      1      2  original sound - DermDoctor | Dr. Shah   \n",
       "3      1      3                 original sound - 𝐝𝐢𝐧𝐨 🎀   \n",
       "4      1      4           original sound - AfroSamuraiT   \n",
       "\n",
       "                                             hashtag         author   likes  \\\n",
       "0                           @louieveemoonteenmoonfam    louieveedee  297300   \n",
       "1  atodamadre%F0%9F%8F%A7, %F0%9F%A4%99%F0%9F%8F%...       dayz.915  522299   \n",
       "2                       @poblanopepp, dermatographia     dermdoctor  430100   \n",
       "3  @lashedchars, fy, fyp, fyp%E3%82%B7%E3%82%9Avi...     marschvarl     251   \n",
       "4         lifehack, lifehacks, challenge, ksi, prime  afrosamuraitt   65200   \n",
       "\n",
       "   comments  shares   saves collectionTime  \\\n",
       "0      1571   20300     721    02-14-16-57   \n",
       "1      3713   36500  142900    02-14-16-57   \n",
       "2      4758   24900    6591    02-14-16-57   \n",
       "3        29      31       0    02-14-16-57   \n",
       "4      3487   11700     189    02-14-16-57   \n",
       "\n",
       "                                              postID  \n",
       "0      original sound - ®️ Louieveegang💙_louieveedee  \n",
       "1                  original sound - dayz915_dayz.915  \n",
       "2  original sound - DermDoctor | Dr. Shah_dermdoctor  \n",
       "3                 original sound - 𝐝𝐢𝐧𝐨 🎀_marschvarl  \n",
       "4        original sound - AfroSamuraiT_afrosamuraitt  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(control_df['hashtag'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "### 2. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>index</th>\n",
       "      <th>music</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>saves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>original sound - ESPN</td>\n",
       "      <td>@wendy.bri, snow, cold</td>\n",
       "      <td>espn</td>\n",
       "      <td>2000000</td>\n",
       "      <td>19900</td>\n",
       "      <td>170800</td>\n",
       "      <td>108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I Have No Enemies - ★DGK132105</td>\n",
       "      <td>@asianjeffontop, toastyog, streamer, fortnite,...</td>\n",
       "      <td>toasty1k</td>\n",
       "      <td>51200</td>\n",
       "      <td>441</td>\n",
       "      <td>3322</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Asn - thsituan._.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccabots</td>\n",
       "      <td>203000</td>\n",
       "      <td>4712</td>\n",
       "      <td>124700</td>\n",
       "      <td>3817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Like That Sped Up - Laila!</td>\n",
       "      <td>@bareandneutral, ingrown</td>\n",
       "      <td>dermdoctor</td>\n",
       "      <td>357800</td>\n",
       "      <td>561</td>\n",
       "      <td>11300</td>\n",
       "      <td>2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>original sound - Funny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baby_ok7</td>\n",
       "      <td>3100000</td>\n",
       "      <td>34500</td>\n",
       "      <td>378200</td>\n",
       "      <td>81300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  index                           music  \\\n",
       "0      1      0           original sound - ESPN   \n",
       "1      1      1  I Have No Enemies - ★DGK132105   \n",
       "2      1      2               Asn - thsituan._.   \n",
       "3      1      3      Like That Sped Up - Laila!   \n",
       "4      1      4          original sound - Funny   \n",
       "\n",
       "                                             hashtag      author    likes  \\\n",
       "0                             @wendy.bri, snow, cold        espn  2000000   \n",
       "1  @asianjeffontop, toastyog, streamer, fortnite,...    toasty1k    51200   \n",
       "2                                                NaN     ccabots   203000   \n",
       "3                           @bareandneutral, ingrown  dermdoctor   357800   \n",
       "4                                                NaN    baby_ok7  3100000   \n",
       "\n",
       "   comments  shares   saves  \n",
       "0     19900  170800  108600  \n",
       "1       441    3322      59  \n",
       "2      4712  124700    3817  \n",
       "3       561   11300    2068  \n",
       "4     34500  378200   81300  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourpath = \"data\" # make sure this is the same path of your data files\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(ourpath, onlyAllData[0])) # get the first file\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "music        0\n",
       "author       0\n",
       "hashtag    475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df_all[['music','author', 'hashtag']].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@wendy.bri', ' snow', ' cold']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['hashtag'][0].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "### 3. Jaccard Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function for calculating jaccard index\n",
    "\n",
    "def jaccard_index(list_1, list_2):\n",
    "    intersection = len(list_1.intersection(list_2))\n",
    "    union = len(list_1.union(list_2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "### 4. Visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
